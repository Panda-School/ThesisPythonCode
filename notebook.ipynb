{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stable Diffusion Counterfactual Image generation\n",
    "Using libraries from huggingface and the open source model Stable Diffusion 3.5-large or medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import interpreter_login\n",
    "interpreter_login()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model\n",
    "loading the model using huggingface's diffuser library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusion3Img2ImgPipeline\n",
    "\n",
    "pipe = StableDiffusion3Img2ImgPipeline.from_pretrained(\"stabilityai/stable-diffusion-3-large\", torch_dtype=torch.bfloat16).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset\n",
    "Load the generated dataset containing only neutral relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'annotator_labels': ['neutral'],\n",
       " 'captionID': '3416050480.jpg#4',\n",
       " 'gold_label': 'neutral',\n",
       " 'pairID': '3416050480.jpg#4r1n',\n",
       " 'sentence1': 'A person on a horse jumps over a broken down airplane.',\n",
       " 'sentence1_binary_parse': '( ( ( A person ) ( on ( a horse ) ) ) ( ( jumps ( over ( a ( broken ( down airplane ) ) ) ) ) . ) )',\n",
       " 'sentence1_parse': '(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN on) (NP (DT a) (NN horse)))) (VP (VBZ jumps) (PP (IN over) (NP (DT a) (JJ broken) (JJ down) (NN airplane)))) (. .)))',\n",
       " 'sentence2': 'A person is training his horse for a competition.',\n",
       " 'sentence2_binary_parse': '( ( A person ) ( ( is ( ( training ( his horse ) ) ( for ( a competition ) ) ) ) . ) )',\n",
       " 'sentence2_parse': '(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) (VP (VBG training) (NP (PRP$ his) (NN horse)) (PP (IN for) (NP (DT a) (NN competition))))) (. .)))'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "import json\n",
    "\n",
    "with open(\"./dataset/snli_1.0_train_neutral.jsonl\", \"r\") as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test drive first entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import get_url\n",
    "import requests\n",
    "import torch\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "caption_id: str = data[0]['captionID'].split(\"#\")[0]\n",
    "\n",
    "url: str = get_url(caption_id, local=False)\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "\n",
    "prompt = data[0]['sentence2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genImage = pipe(\n",
    "    prompt=prompt, \n",
    "    image=image, \n",
    "    num_inference_steps=30, \n",
    "    guidance_scale=7.5).images[0]\n",
    "\n",
    "genImage.save(f\"output/{data[0]['captionID']}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating test image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Clip score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.multimodal import CLIPScore\n",
    "\n",
    "clip = CLIPScore(model_name_or_path=\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "score = clip(genImage, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fr√©chet inception distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\beheerder\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\beheerder\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 610.7946166992188\n"
     ]
    }
   ],
   "source": [
    "from fid import compute_fid_between_images\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "caption_id2: str = data[1]['captionID'].split(\"#\")[0]\n",
    "\n",
    "url: str = get_url(caption_id2, local=False)\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "image2 = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "\n",
    "# Example usage:\n",
    "fid_score = compute_fid_between_images(image, image2)\n",
    "print(f'FID score: {fid_score}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
